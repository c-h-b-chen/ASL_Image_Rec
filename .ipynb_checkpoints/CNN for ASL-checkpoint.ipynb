{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from vis_utils import *\n",
    "import random;\n",
    "import math;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.sheed(1)\n",
    "num_epochs = 5;\n",
    "batch_size = 100;\n",
    "learning_rate = 0.001;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLdataset(Dataset):\n",
    "    '''ASL Dataset'''\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file\n",
    "            transform (callable): Optional transform to apply to sample\n",
    "        \"\"\"\n",
    "        \n",
    "        data = pd.read_csv(csv_file);\n",
    "        self.X = np.array(data.iloc[:, 1:]).reshape(-1, 1, 75, 75)#.astype(float);\n",
    "        self.Y = np.array(data.iloc[:, 0]);\n",
    "        \n",
    "        del data;\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X);\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx];\n",
    "        label = self.Y[idx];\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item);\n",
    "        \n",
    "        return (item, label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ASLdataset(csv_file='transformed_data');\n",
    "test_dataset = ASLdataset(csv_file='tbd.csv')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True);\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'a', 1 : 'b', 2 : 'c', 3 : 'd', 4 : 'e', 5 : 'f', 6 : 'g',\n",
    "              7 : 'h', 8 : 'i', 9 : 'j', 10 : 'k', 11: 'l', 12: 'm', 13: 'n',\n",
    "              14 : 'o', 15 : 'p', 16 : 'q', 17 : 'r', 18 : 's', 19 : 't', 20 : 'u', \n",
    "              21 : 'v', 22 : 'w', 23 : 'x', 24 : 'y', 25 : 'z', 26 : 'nothing'};\n",
    "fig = plt.figure(figsize=(5,5));\n",
    "columns = 4;\n",
    "rows = 7;\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_xy = np.random.randint(len(train_dataset));\n",
    "    img = train_dataset[img_xy][0][0,:,:]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels_map[train_dataset[img_xy][1]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "#instance of the Conv Net\n",
    "cnn = CNN();\n",
    "cnn.cuda()\n",
    "#loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.float()\n",
    "        images = Variable(images.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data[0]);\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.float()\n",
    "    images = Variable(images.cuda())\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Test Accuracy of the model on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
